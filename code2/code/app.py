# app.py
import os, re, json
import google.generativeai as genai
import time
from typing import List, Dict, Any, Tuple
from flask import Flask, request, jsonify, render_template
from routes.admin import admin_bp
from flask_cors import CORS
from dotenv import load_dotenv
from flask import Flask
from flask_socketio import SocketIO

load_dotenv()
genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))

GMODEL = genai.GenerativeModel(
    "gemini-2.5-pro",
    system_instruction=(
        "You may receive text where personally identifiable information is replaced with "
        "placeholders like [PHONE], [EMAIL], [CARD], [ADDRESS], [JWT], [UUID], etc. "
        "Do NOT attempt to reconstruct hidden values. Answer using the available context. "
        "If the exact value is required to proceed, say so and explain what non-sensitive info you need instead."
    ),
)

# â”€â”€ Flask â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)
socketio = SocketIO(app) # 2. SocketIO ê°ì²´ ìƒì„±
CORS(app, origins=["http://localhost:8080", "http://127.0.0.1:8080", "http://localhost:8081", "http://127.0.0.1:8081", "null"])

app.register_blueprint(admin_bp)

@app.route("/")
def index():
    # templates í´ë” ì•ˆì— ìˆëŠ” login.html íŒŒì¼ì„ í™”ë©´ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
    return render_template("login.html")

@app.route("/admin")
def admin_page():
    # TODO: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì„¸ì…˜ ë“±ì„ í™•ì¸í•´ì„œ
    # ê´€ë¦¬ìê°€ ì•„ë‹ ê²½ìš° ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë³´ë‚´ëŠ” ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.
    return render_template("admin.html")

@app.route("/chat")
def chat_page():
    return render_template("Chat Proxy.html")

# â”€â”€ íŒ¨í„´ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PATTERNS: List[Dict[str, Any]] = json.load(open("patterns.json","r",encoding="utf-8"))["sensitive_patterns"]

def luhn_ok(s: str) -> bool:
    digits = [int(c) for c in re.sub(r"\D","", s)]
    if not (13 <= len(digits) <= 19): return False
    total = 0; parity = len(digits) % 2
    for i, d in enumerate(digits):
        if i % 2 == parity:
            d *= 2
            if d > 9: d -= 9
        total += d
    return total % 10 == 0

def apply_patterns(text: str) -> Tuple[str, List[Dict[str,Any]]]:
    """BLOCK -> MASK -> GENERALIZE ìˆœì„œë¡œ ì ìš©í•˜ê³ , íƒì§€ë‚´ì—­ì„ ë°˜í™˜"""
    masked = text
    findings: List[Dict[str,Any]] = []
    priority = {"block":0, "mask":1, "generalize":2}
    # ì´ë¯¸ ë§ˆìŠ¤í‚¹ëœ í† í° ë°©ì§€ìš©: ì¹˜í™˜ í† í° íŒ¨í„´
    guard = re.compile(r"\[(PHONE|CARD|EMAIL|IP|JWT|UUID|MAC|ADDRESS|ACCOUNT|TOKEN|PASSPORT|DRIVER_LICENSE|CREDENTIAL)\]")

    for p in sorted(PATTERNS, key=lambda x: priority.get(x["action"], 3)):
        rx = re.compile(p["regex"])
        def _repl(m):
            val = m.group(0)
            # ì¬ë§ˆìŠ¤í‚¹ ë°©ì§€
            if guard.search(val): return val
            # validator (ì˜ˆ: Luhn)
            if p.get("validator") == "LUHN" and not luhn_ok(val):
                return val
            findings.append({"name": p["name"], "value": val, "action": p["action"]})
            if p["action"] == "block":
                # BLOCKì€ ì¦‰ì‹œ ì˜ˆì™¸
                raise ValueError(p.get("message", p["name"]))
            # ì¹˜í™˜
            rep = p.get("replacement", "[REDACTED]")
            # ë°±ì°¸ì¡°(\1 ë“±) ì§€ì›: ë¶€ë¶„ ë¬¸ìì—´ì— ë‹¤ì‹œ ì •ê·œì‹ì„ ì“°ë©´ ëŠë¦¬ë‹ˆ group ì¹˜í™˜ë§Œ ì²˜ë¦¬
            try:
                # ê°„ë‹¨ì¹˜í™˜: \1 ë“±ì˜ ë°±ì°¸ì¡°ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                if r"\1" not in rep and r"\2" not in rep:
                    return rep
                # ë°±ì°¸ì¡°ê°€ ìˆìœ¼ë©´ ì›ë³¸ ë§¤ì¹˜ì—ë§Œ ì ìš©
                return re.sub(rx, rep, val)
            except re.error:
                return rep
        masked = rx.sub(_repl, masked)
    return masked, findings

# â”€â”€ 2ë‹¨ê³„(ê·¸ë ˆì´ì¡´) íŒì •: Geminiì— ë¬»ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤ì œ êµ¬í˜„: Gemini API(ì„œë²„ì¸¡) í˜¸ì¶œë¡œ êµì²´í•˜ì„¸ìš”. ì—¬ê¸´ ë°ëª¨ ë¡œì§.
def judge_sensitive_with_gemini(text: str) -> List[Dict[str,Any]]:
    """
    Geminiì—ê²Œ â€˜JSONë§Œâ€™ ë‹¬ë¼ê³  í•˜ê³ , íŒŒì‹± ì‹¤íŒ¨ì— ëŒ€ë¹„í•´ ë°±ì—… íŒŒì„œë„ ì‚¬ìš©.
    """
    prompt = f"""
ë‹¤ìŒ ë¬¸ì¥ì— ê°œì¸ì •ë³´ ìœ„í—˜ì´ ìˆëŠ” êµ¬ê°„ì„ ì°¾ì•„ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
í˜•ì‹ ì˜ˆì‹œ:
[{{"span":[10,22],"label":"NAME","action":"mask"}}]
ë¼ë²¨ì€ NAME, ADDRESS, ORG, EMAIL, PHONE, ETC ì¤‘ í•˜ë‚˜.
ì• ë§¤í•˜ë©´ actionì€ "mask", í™•ì‹¤íˆ ìœ ì¶œ ìœ„í—˜ì´ë©´ "block".
ë¬¸ì¥:
{text}
JSON ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
"""
    try:
        resp = GMODEL.generate_content(prompt)
        raw = (resp.text or "").strip()
        # JSONë§Œ ì¶”ì¶œ(ì‹¤ìˆ˜ë¡œ í…ìŠ¤íŠ¸ê°€ ì„ì¼ ê²½ìš° ëŒ€ë¹„)
        m = re.search(r"\[\s*\{.*\}\s*\]", raw, re.S)
        arr = json.loads(m.group(0) if m else raw)
        # í˜•ì‹ ì •ê·œí™”
        out = []
        for j in arr:
            if not isinstance(j, dict): continue
            span = j.get("span")
            if not (isinstance(span, list) and len(span)==2 and all(isinstance(x,int) for x in span)):
                continue
            out.append({
                "span": span,
                "label": j.get("label","ETC"),
                "action": "block" if j.get("action")=="block" else "mask"
            })
        return out
    except Exception as e:
        print("[judge_sensitive_with_gemini] error:", e)
        return []

def apply_gemini_judgement(text: str, judgements: List[Dict[str,Any]]) -> Tuple[str, List[Dict[str,Any]]]:
    """Gemini íŒì • ê²°ê³¼ëŒ€ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë§ˆìŠ¤í‚¹/ì°¨ë‹¨"""
    if not judgements: return text, []
    out = []
    # span ì¹˜í™˜ì€ ë’¤ì—ì„œë¶€í„° ì ìš©(ì¸ë±ìŠ¤ ì•ˆì •)
    for j in sorted(judgements, key=lambda x: x["span"][0], reverse=True):
        s, e = j["span"]
        val = text[s:e]
        act = j.get("action","mask")
        if act == "block":
            raise ValueError(f"ëª¨ë¸ íŒì • ì°¨ë‹¨: {j.get('label','SENSITIVE')}")
        rep = j.get("replacement", f"[{j.get('label','SENSITIVE')}]")
        text = text[:s] + rep + text[e:]
        out.append({"name": j.get("label","SENSITIVE"), "value": val, "action": act})
    return text, list(reversed(out))

# â”€â”€ Gemini ë‹µë³€ ìƒì„±(ì„œë²„ì¸¡) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_gemini_generate(model_id: str, messages: List[Dict[str, str]]) -> str:
    """
    ì „ì²˜ë¦¬ë¡œ ë§ˆìŠ¤í‚¹ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•´ ì‹¤ì œ ë‹µë³€ì„ ë°›ëŠ”ë‹¤.
    - history: ë§ˆì§€ë§‰ ìœ ì € ë°œí™” ì§ì „ê¹Œì§€
    - send_message: ë§ˆì§€ë§‰ ìœ ì € ë°œí™”(ë¹ˆ ë¬¸ìì—´ ê¸ˆì§€)
    """
    # 1) ëª¨ë¸ ê°ì²´ ì„ íƒ (UIì—ì„œ ë°›ì€ model_idê°€ ì—†ê±°ë‚˜ ê¸°ë³¸ì´ë©´ ì „ì—­ GMODEL ì‚¬ìš©)
    if model_id and model_id != "demo-local" and not model_id.lower().startswith("gpt-"):
        gmodel = genai.GenerativeModel(
            model_id,
            system_instruction=getattr(GMODEL, "_system_instruction", None)
        )
    else:
        # demo-localì´ë‚˜ gpt-*ê°€ ë“¤ì–´ì˜¤ë©´ ë°ëª¨ ì—ì½” ìœ ì§€ (ì›í•˜ë©´ ì—¬ê¸°ì„œë„ Geminië¡œ ë¼ìš°íŒ… ê°€ëŠ¥)
        last = next((m for m in reversed(messages) if m["role"]=="user"), {"content":""})
        return f"ì…ë ¥ ìš”ì•½: {last['content'][:120]}"

    # 2) ë§ˆì§€ë§‰ ìœ ì € ë°œí™”
    last_user_idx = next((i for i in range(len(messages)-1, -1, -1) if messages[i]["role"] == "user"), None)
    if last_user_idx is None:
        return "(no user message)"
    last_user = (messages[last_user_idx].get("content") or "").strip()
    if not last_user:
        return "(empty user message)"

    # 3) ê³¼ê±° ëŒ€í™” â†’ historyë¡œ (ë§ˆì§€ë§‰ ìœ ì € ì´ì „ê¹Œì§€ë§Œ)
    history = []
    for m in messages[:last_user_idx]:
        role = "user" if m["role"] == "user" else "model"
        content = (m.get("content") or "").strip()
        if content:
            history.append({"role": role, "parts": [content]})

    # 4) ì±„íŒ… í˜¸ì¶œ
    chat = gmodel.start_chat(history=history)
    resp = chat.send_message(last_user)

    return getattr(resp, "text", "") or "(empty response)"

@app.get("/admin/logs")
def get_logs():
    try:
        with open("logs.json", "r", encoding="utf-8") as f:
            logs = json.load(f)
        return jsonify(logs)
    except (FileNotFoundError, json.JSONDecodeError):
        return jsonify([])
        
# â”€â”€ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
def health():
    return {"ok": True}

import time

#ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def _save_log_entry(log_entry):
    """ë¡œê·¸ í•­ëª© í•˜ë‚˜ë¥¼ logs.json íŒŒì¼ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    try:
        with open("logs.json", "r", encoding="utf-8") as f:
            logs = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        logs = []
    logs.append(log_entry)
    with open("logs.json", "w", encoding="utf-8") as f:
        json.dump(logs, f, indent=2, ensure_ascii=False)
    
    # with ë¸”ë¡ì´ ëë‚œ í›„, ë…ë¦½ì ìœ¼ë¡œ ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.
    socketio.emit('stats_updated', {'message': 'New log entry saved'})



        
@app.post("/login")
def login():
    data = request.get_json(force=True)
    user_id = data.get("id")
    password = data.get("password")

    try:
        with open("users.json", "r", encoding="utf-8") as f:
            users_data = json.load(f)
            users = users_data.get("users", [])
    except (FileNotFoundError, json.JSONDecodeError):
        return jsonify({"error": "ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500

    for user in users:
        if user["id"] == user_id and user["password"] == password:
            return jsonify({"success": True, "role": user["role"]})

    return jsonify({"error": "ë¡œê·¸ì¸ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 401

@app.post("/chat")
def chat():
    t0 = time.perf_counter()
    data = request.get_json(force=True)
    model_id = data.get("model", "gemini-2.5-pro")
    messages: List[Dict[str,str]] = data.get("messages", [])

    idx = next((i for i in range(len(messages)-1, -1, -1) if messages[i]["role"]=="user"), None)
    if idx is None: return jsonify({"error": "ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
    orig = messages[idx]["content"]
    
    # --- 1ì°¨ í•„í„°ë§ ---
    try:
        sanitized_1, fin_in = apply_patterns(orig)
    except ValueError as e:
        log_entry = {
            "timestamp": time.time(), "user": "temp_user@company.com", "user_prompt": orig,
            "action": "block", "pii": [str(e)], "processed_prompt_for_llm": "BLOCKED",
            "llm_response": "N/A", "detections_in": [{"name": str(e), "value": "N/A", "action": "block"}],
            "detections_out": []
        }
        _save_log_entry(log_entry)
        return jsonify({"error":"ë¯¼ê°ì •ë³´ê°€ í¬í•¨ë˜ì–´ ì „ì†¡ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.","detail":str(e)}), 400
    
    t1 = time.perf_counter()

    # --- 2ì°¨(ëª¨ë¸ íŒì •) ---
    judgements = judge_sensitive_with_gemini(sanitized_1)
    try:
        sanitized_2, fin_in_model = apply_gemini_judgement(sanitized_1, judgements)
    except ValueError as e:
        # â–¼â–¼â–¼â–¼â–¼ ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ â–¼â–¼â–¼â–¼â–¼
        log_entry = {
            "timestamp": time.time(), "user": "temp_user@company.com", "user_prompt": orig,
            "action": "block", "pii": [str(e)], "processed_prompt_for_llm": "BLOCKED_BY_AI",
            "llm_response": "N/A", "detections_in": fin_in + [{"name": str(e), "value": "N/A", "action": "block"}],
            "detections_out": []
        }
        _save_log_entry(log_entry) # 2ë‹¨ê³„ ì°¨ë‹¨ ë¡œê·¸ ì €ì¥
        # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
        return jsonify({"error":"ë¯¼ê°ì •ë³´ê°€ í¬í•¨ë˜ì–´ ì „ì†¡ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.","detail":str(e)}), 400
    
    t2 = time.perf_counter()

    # --- ëª¨ë¸ í˜¸ì¶œ, ì¶œë ¥ í•„í„° ë“± ---
    sanitized_messages = messages[:]
    sanitized_messages[idx] = {"role":"user", "content": sanitized_2}
    llm_resp = call_gemini_generate(model_id, sanitized_messages)
    t3 = time.perf_counter()
    sanitized_out, fin_out = apply_patterns(llm_resp)
    t4 = time.perf_counter()

    # --- ì„±ê³µ ì‹œ ë¡œê·¸ ì €ì¥ ---
    log_entry = {
        "timestamp": time.time(), "user": "temp_user@company.com", "user_prompt": orig,
        "action": "mask", "pii": [d['name'] for d in (fin_in + fin_in_model)],
        "processed_prompt_for_llm": sanitized_2, "llm_response": llm_resp,
        "detections_in": fin_in + fin_in_model, "detections_out": fin_out
    }
    _save_log_entry(log_entry)

    # 1. ë§ˆìŠ¤í‚¹ëœ í•­ëª©ë“¤ì˜ ì´ë¦„ë§Œ ì¶”ì¶œ (ì˜ˆ: ['ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼'])
    detected_names = [d['name'] for d in (fin_in + fin_in_model)]

    # 2. ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„±
    security_notice = None
    if detected_names:
        # ì¤‘ë³µ ì œê±° í›„ ë³´ê¸° ì¢‹ê²Œ í•©ì¹¨ (ì˜ˆ: "ì „í™”ë²ˆí˜¸, ì´ë©”ì¼")
        unique_names = ", ".join(sorted(list(set(detected_names))))
        security_notice = f"ğŸ›¡ï¸ ì…ë ¥í•˜ì‹  ë‚´ìš© ì¤‘ {unique_names} í•­ëª©ì´ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."

    # 3. ìµœì¢… ì‘ë‹µ ë°ì´í„° êµ¬ì„± (ê¸°ì¡´ meta ëŒ€ì‹  notice ì „ë‹¬)
    return jsonify({
        "content": sanitized_out,
        "notice": security_notice
    })

if __name__ == "__main__":
    app.run(host=os.getenv("HOST","0.0.0.0"), port=int(os.getenv("PORT","8081")), debug=True)
